{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOKFFaJPU6RPFlLa5JX2JWk"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from  google.colab import drive\n","drive.mount('/content/drive')\n","\n","dataset = pd.read_csv(\"/content/drive/My Drive/Colab Notebooks/Bank_Predictions.csv\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"v5u8FMR4zGKG","executionInfo":{"status":"ok","timestamp":1696525489409,"user_tz":240,"elapsed":1209,"user":{"displayName":"Daram Vinay","userId":"14977385088883064320"}},"outputId":"cedf5c26-22d3-470d-f465-3a6e34812405"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Lmwz2WUXyvPh","executionInfo":{"status":"ok","timestamp":1696526167632,"user_tz":240,"elapsed":393950,"user":{"displayName":"Daram Vinay","userId":"14977385088883064320"}},"outputId":"cde17abc-93cb-47e3-9290-c0e4e8053fcc"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","800/800 [==============================] - 5s 4ms/step - loss: 0.5302 - accuracy: 0.7405\n","Epoch 2/100\n","800/800 [==============================] - 3s 4ms/step - loss: 0.3357 - accuracy: 0.8070\n","Epoch 3/100\n","800/800 [==============================] - 4s 5ms/step - loss: 0.1763 - accuracy: 0.9421\n","Epoch 4/100\n","800/800 [==============================] - 4s 5ms/step - loss: 0.0924 - accuracy: 0.9855\n","Epoch 5/100\n","800/800 [==============================] - 3s 4ms/step - loss: 0.0748 - accuracy: 0.9825\n","Epoch 6/100\n","800/800 [==============================] - 3s 4ms/step - loss: 0.0495 - accuracy: 0.9896\n","Epoch 7/100\n","800/800 [==============================] - 4s 5ms/step - loss: 0.0610 - accuracy: 0.9814\n","Epoch 8/100\n","800/800 [==============================] - 4s 5ms/step - loss: 0.0617 - accuracy: 0.9825\n","Epoch 9/100\n","800/800 [==============================] - 3s 4ms/step - loss: 0.0539 - accuracy: 0.9844\n","Epoch 10/100\n","800/800 [==============================] - 3s 4ms/step - loss: 0.0476 - accuracy: 0.9875\n","Epoch 11/100\n","800/800 [==============================] - 3s 4ms/step - loss: 0.0444 - accuracy: 0.9887\n","Epoch 12/100\n","800/800 [==============================] - 4s 6ms/step - loss: 0.0437 - accuracy: 0.9889\n","Epoch 13/100\n","800/800 [==============================] - 3s 4ms/step - loss: 0.0432 - accuracy: 0.9889\n","Epoch 14/100\n","800/800 [==============================] - 3s 4ms/step - loss: 0.0420 - accuracy: 0.9889\n","Epoch 15/100\n","800/800 [==============================] - 3s 4ms/step - loss: 0.0405 - accuracy: 0.9889\n","Epoch 16/100\n","800/800 [==============================] - 5s 6ms/step - loss: 0.0641 - accuracy: 0.9779\n","Epoch 17/100\n","800/800 [==============================] - 3s 4ms/step - loss: 0.0568 - accuracy: 0.9801\n","Epoch 18/100\n","800/800 [==============================] - 3s 4ms/step - loss: 0.0281 - accuracy: 0.9923\n","Epoch 19/100\n","800/800 [==============================] - 3s 4ms/step - loss: 0.0192 - accuracy: 0.9962\n","Epoch 20/100\n","800/800 [==============================] - 5s 6ms/step - loss: 0.0167 - accuracy: 0.9966\n","Epoch 21/100\n","800/800 [==============================] - 3s 4ms/step - loss: 0.0157 - accuracy: 0.9966\n","Epoch 22/100\n","800/800 [==============================] - 3s 4ms/step - loss: 0.0155 - accuracy: 0.9966\n","Epoch 23/100\n","800/800 [==============================] - 3s 4ms/step - loss: 0.0153 - accuracy: 0.9966\n","Epoch 24/100\n","800/800 [==============================] - 5s 6ms/step - loss: 0.0150 - accuracy: 0.9966\n","Epoch 25/100\n","800/800 [==============================] - 3s 4ms/step - loss: 0.0146 - accuracy: 0.9966\n","Epoch 26/100\n","800/800 [==============================] - 3s 4ms/step - loss: 0.0142 - accuracy: 0.9966\n","Epoch 27/100\n","800/800 [==============================] - 3s 4ms/step - loss: 0.0139 - accuracy: 0.9966\n","Epoch 28/100\n","800/800 [==============================] - 5s 6ms/step - loss: 0.0136 - accuracy: 0.9966\n","Epoch 29/100\n","800/800 [==============================] - 3s 4ms/step - loss: 0.0141 - accuracy: 0.9966\n","Epoch 30/100\n","800/800 [==============================] - 3s 4ms/step - loss: 0.0130 - accuracy: 0.9966\n","Epoch 31/100\n","800/800 [==============================] - 3s 4ms/step - loss: 0.0128 - accuracy: 0.9966\n","Epoch 32/100\n","800/800 [==============================] - 5s 6ms/step - loss: 0.0126 - accuracy: 0.9966\n","Epoch 33/100\n","800/800 [==============================] - 3s 4ms/step - loss: 0.0123 - accuracy: 0.9966\n","Epoch 34/100\n","800/800 [==============================] - 3s 4ms/step - loss: 0.0124 - accuracy: 0.9966\n","Epoch 35/100\n","800/800 [==============================] - 4s 5ms/step - loss: 0.0112 - accuracy: 0.9966\n","Epoch 36/100\n","800/800 [==============================] - 6s 7ms/step - loss: 0.0112 - accuracy: 0.9965\n","Epoch 37/100\n","800/800 [==============================] - 5s 6ms/step - loss: 0.0113 - accuracy: 0.9965\n","Epoch 38/100\n","800/800 [==============================] - 3s 4ms/step - loss: 0.0107 - accuracy: 0.9966\n","Epoch 39/100\n","800/800 [==============================] - 5s 6ms/step - loss: 0.0106 - accuracy: 0.9966\n","Epoch 40/100\n","800/800 [==============================] - 4s 5ms/step - loss: 0.0105 - accuracy: 0.9966\n","Epoch 41/100\n","800/800 [==============================] - 3s 4ms/step - loss: 0.0105 - accuracy: 0.9966\n","Epoch 42/100\n","800/800 [==============================] - 3s 4ms/step - loss: 0.0105 - accuracy: 0.9966\n","Epoch 43/100\n","800/800 [==============================] - 5s 6ms/step - loss: 0.0104 - accuracy: 0.9966\n","Epoch 44/100\n","800/800 [==============================] - 4s 4ms/step - loss: 0.0104 - accuracy: 0.9966\n","Epoch 45/100\n","800/800 [==============================] - 3s 4ms/step - loss: 0.0103 - accuracy: 0.9966\n","Epoch 46/100\n","800/800 [==============================] - 3s 4ms/step - loss: 0.0103 - accuracy: 0.9966\n","Epoch 47/100\n","800/800 [==============================] - 5s 6ms/step - loss: 0.0109 - accuracy: 0.9966\n","Epoch 48/100\n","800/800 [==============================] - 3s 4ms/step - loss: 0.0101 - accuracy: 0.9966\n","Epoch 49/100\n","800/800 [==============================] - 3s 4ms/step - loss: 0.0100 - accuracy: 0.9966\n","Epoch 50/100\n","800/800 [==============================] - 3s 4ms/step - loss: 0.0100 - accuracy: 0.9966\n","Epoch 51/100\n","800/800 [==============================] - 5s 6ms/step - loss: 0.0100 - accuracy: 0.9966\n","Epoch 52/100\n","800/800 [==============================] - 3s 4ms/step - loss: 0.0100 - accuracy: 0.9966\n","Epoch 53/100\n","800/800 [==============================] - 4s 5ms/step - loss: 0.0100 - accuracy: 0.9966\n","Epoch 54/100\n","800/800 [==============================] - 3s 4ms/step - loss: 0.0099 - accuracy: 0.9966\n","Epoch 55/100\n","800/800 [==============================] - 5s 6ms/step - loss: 0.0099 - accuracy: 0.9966\n","Epoch 56/100\n","800/800 [==============================] - 3s 4ms/step - loss: 0.0100 - accuracy: 0.9966\n","Epoch 57/100\n","800/800 [==============================] - 3s 4ms/step - loss: 0.0099 - accuracy: 0.9966\n","Epoch 58/100\n","800/800 [==============================] - 3s 4ms/step - loss: 0.0099 - accuracy: 0.9966\n","Epoch 59/100\n","800/800 [==============================] - 5s 7ms/step - loss: 0.0099 - accuracy: 0.9966\n","Epoch 60/100\n","800/800 [==============================] - 3s 4ms/step - loss: 0.0099 - accuracy: 0.9966\n","Epoch 61/100\n","800/800 [==============================] - 3s 4ms/step - loss: 0.0099 - accuracy: 0.9966\n","Epoch 62/100\n","800/800 [==============================] - 4s 4ms/step - loss: 0.0103 - accuracy: 0.9966\n","Epoch 63/100\n","800/800 [==============================] - 5s 6ms/step - loss: 0.0100 - accuracy: 0.9966\n","Epoch 64/100\n","800/800 [==============================] - 3s 4ms/step - loss: 0.0097 - accuracy: 0.9966\n","Epoch 65/100\n","800/800 [==============================] - 3s 4ms/step - loss: 0.0097 - accuracy: 0.9966\n","Epoch 66/100\n","800/800 [==============================] - 3s 4ms/step - loss: 0.0097 - accuracy: 0.9966\n","Epoch 67/100\n","800/800 [==============================] - 5s 6ms/step - loss: 0.0096 - accuracy: 0.9966\n","Epoch 68/100\n","800/800 [==============================] - 5s 6ms/step - loss: 0.0096 - accuracy: 0.9966\n","Epoch 69/100\n","800/800 [==============================] - 4s 5ms/step - loss: 0.0095 - accuracy: 0.9966\n","Epoch 70/100\n","800/800 [==============================] - 5s 6ms/step - loss: 0.0095 - accuracy: 0.9966\n","Epoch 71/100\n","800/800 [==============================] - 4s 5ms/step - loss: 0.0095 - accuracy: 0.9966\n","Epoch 72/100\n","800/800 [==============================] - 3s 4ms/step - loss: 0.0095 - accuracy: 0.9966\n","Epoch 73/100\n","800/800 [==============================] - 3s 4ms/step - loss: 0.0095 - accuracy: 0.9966\n","Epoch 74/100\n","800/800 [==============================] - 4s 5ms/step - loss: 0.0095 - accuracy: 0.9966\n","Epoch 75/100\n","800/800 [==============================] - 4s 5ms/step - loss: 0.0099 - accuracy: 0.9966\n","Epoch 76/100\n","800/800 [==============================] - 3s 4ms/step - loss: 0.0096 - accuracy: 0.9966\n","Epoch 77/100\n","800/800 [==============================] - 3s 4ms/step - loss: 0.0095 - accuracy: 0.9966\n","Epoch 78/100\n","800/800 [==============================] - 5s 6ms/step - loss: 0.0095 - accuracy: 0.9966\n","Epoch 79/100\n","800/800 [==============================] - 4s 5ms/step - loss: 0.0095 - accuracy: 0.9966\n","Epoch 80/100\n","800/800 [==============================] - 3s 4ms/step - loss: 0.0095 - accuracy: 0.9966\n","Epoch 81/100\n","800/800 [==============================] - 4s 5ms/step - loss: 0.0095 - accuracy: 0.9966\n","Epoch 82/100\n","800/800 [==============================] - 5s 6ms/step - loss: 0.0095 - accuracy: 0.9966\n","Epoch 83/100\n","800/800 [==============================] - 4s 5ms/step - loss: 0.0095 - accuracy: 0.9966\n","Epoch 84/100\n","800/800 [==============================] - 3s 4ms/step - loss: 0.0095 - accuracy: 0.9966\n","Epoch 85/100\n","800/800 [==============================] - 3s 4ms/step - loss: 0.0095 - accuracy: 0.9966\n","Epoch 86/100\n","800/800 [==============================] - 5s 6ms/step - loss: 0.0095 - accuracy: 0.9966\n","Epoch 87/100\n","800/800 [==============================] - 3s 4ms/step - loss: 0.0095 - accuracy: 0.9966\n","Epoch 88/100\n","800/800 [==============================] - 3s 4ms/step - loss: 0.0097 - accuracy: 0.9966\n","Epoch 89/100\n","800/800 [==============================] - 3s 4ms/step - loss: 0.0097 - accuracy: 0.9966\n","Epoch 90/100\n","800/800 [==============================] - 5s 6ms/step - loss: 0.0094 - accuracy: 0.9966\n","Epoch 91/100\n","800/800 [==============================] - 4s 5ms/step - loss: 0.0094 - accuracy: 0.9966\n","Epoch 92/100\n","800/800 [==============================] - 3s 4ms/step - loss: 0.0094 - accuracy: 0.9966\n","Epoch 93/100\n","800/800 [==============================] - 3s 4ms/step - loss: 0.0094 - accuracy: 0.9966\n","Epoch 94/100\n","800/800 [==============================] - 5s 6ms/step - loss: 0.0094 - accuracy: 0.9966\n","Epoch 95/100\n","800/800 [==============================] - 4s 5ms/step - loss: 0.0094 - accuracy: 0.9966\n","Epoch 96/100\n","800/800 [==============================] - 3s 4ms/step - loss: 0.0094 - accuracy: 0.9966\n","Epoch 97/100\n","800/800 [==============================] - 3s 4ms/step - loss: 0.0094 - accuracy: 0.9966\n","Epoch 98/100\n","800/800 [==============================] - 4s 6ms/step - loss: 0.0094 - accuracy: 0.9966\n","Epoch 99/100\n","800/800 [==============================] - 4s 5ms/step - loss: 0.0094 - accuracy: 0.9966\n","Epoch 100/100\n","800/800 [==============================] - 3s 4ms/step - loss: 0.0094 - accuracy: 0.9966\n","63/63 [==============================] - 0s 5ms/step\n"]}],"source":["# Importing the libraries\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","\n","\n","# Importing the dataset\n","X = dataset.iloc[:, 3:13].values\n","y = dataset.iloc[:, 13].values\n","\n","# ------ Part-1: Data preprocessing ----------\n","\n","# Encoding categorical data\n","from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n","labelencoder_X_1 = LabelEncoder()\n","X[:, 1] = labelencoder_X_1.fit_transform(X[:, 1])\n","labelencoder_X_2 = LabelEncoder()\n","X[:, 2] = labelencoder_X_2.fit_transform(X[:, 2])\n","onehotencoder = OneHotEncoder(categories = 'auto')\n","X = onehotencoder.fit_transform(X).toarray()\n","X = X[:, 1:]\n","\n","# Splitting the dataset into the Training set and Test set\n","from sklearn.model_selection import train_test_split\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n","\n","# Feature Scaling\n","from sklearn.preprocessing import StandardScaler\n","sc_X = StandardScaler()\n","X_train = sc_X.fit_transform(X_train)\n","X_test = sc_X.transform(X_test)\n","\n","# ------- Part-2: Build the ANN --------\n","\n","# import keras library and packages\n","import keras\n","from keras.models import Sequential\n","from keras.layers import Dense\n","\n","# Initializing the ANN\n","classifier = Sequential()\n","\n","# Adding the input layer and the first hidden layer\n","classifier.add(Dense(units=6, activation='relu', input_dim=X.shape[1]))\n","\n","# Adding the second hidden layer\n","classifier.add(Dense(units=6, activation='relu'))\n","\n","# Adding the output layer\n","classifier.add(Dense(units=1, activation='sigmoid'))\n","\n","# Compiling the ANN\n","classifier.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","\n","# Fitting the ANN to the training set\n","classifier.fit(X_train, y_train, batch_size=10, epochs=100)\n","\n","# Predicting the Test set results\n","y_pred = classifier.predict(X_test)\n","y_pred = (y_pred > 0.5)\n","\n","# Making the confusion Matrix\n","from sklearn.metrics import confusion_matrix\n","cm = confusion_matrix(y_test, y_pred)\n","\n"]},{"cell_type":"code","source":["cm"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ArgMWB8p2EG2","executionInfo":{"status":"ok","timestamp":1696526266698,"user_tz":240,"elapsed":168,"user":{"displayName":"Daram Vinay","userId":"14977385088883064320"}},"outputId":"d4270ac9-80d8-48f7-9d4f-adad7b1d2cde"},"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[1279,  316],\n","       [ 161,  244]])"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["(1279+244)/(1279+244+316+161)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZN_mh6Gv2n5P","executionInfo":{"status":"ok","timestamp":1696526583272,"user_tz":240,"elapsed":149,"user":{"displayName":"Daram Vinay","userId":"14977385088883064320"}},"outputId":"db969581-12b0-4fc1-cc38-54dc7b6b8a4b"},"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.7615"]},"metadata":{},"execution_count":6}]}]}
{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"aa.ipynb","provenance":[],"authorship_tag":"ABX9TyPstmzTxmcv8r8vnrtHLadr"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"z2-TwPyJJne8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1609223508403,"user_tz":-330,"elapsed":1069,"user":{"displayName":"Daram Vinay","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhbNxBWl4t-Cii6_ckmvnzQhPSq9rQmjcxMiQ4t7Q=s64","userId":"14977385088883064320"}},"outputId":"9295b9ea-6048-41fa-ea1a-c08bd16a345b"},"source":["from  google.colab import drive\r\n","drive.mount('/content/drive')\r\n"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"skpD12d1JhKC","colab":{"base_uri":"https://localhost:8080/","height":418},"executionInfo":{"status":"error","timestamp":1609224191476,"user_tz":-330,"elapsed":1163,"user":{"displayName":"Daram Vinay","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhbNxBWl4t-Cii6_ckmvnzQhPSq9rQmjcxMiQ4t7Q=s64","userId":"14977385088883064320"}},"outputId":"0ef28aa8-8a44-41cb-dbf4-d11f4f9cb1e5"},"source":["import sys\r\n","import numpy as np\r\n","from numpy import *\r\n","import csv\r\n","\r\n","class Node:\r\n","    def __init__(self, attribute):\r\n","        self.attribute = attribute\r\n","        self.children = []\r\n","        self.answer = \"\"\r\n","        \r\n","def read_data(filename):\r\n","    \"\"\" read csv file and return header and data  \"\"\"\r\n","    with open(filename, 'r') as csvfile:\r\n","        datareader = csv.reader(csvfile, delimiter=',')\r\n","        metadata = next(datareader)\r\n","        traindata=[]\r\n","        for row in datareader:\r\n","            traindata.append(row)\r\n","            \r\n","    return (metadata, traindata)\r\n","\r\n","\r\n","\r\n","def subtables(data, col, delete):\r\n","    dict = {}\r\n","    items = np.unique(data[:, col]) # get unique values in a particular column\r\n","    \r\n","    count = np.zeros((items.shape[0], 1), dtype=np.int32)   #number of row = number of values \r\n","    \r\n","    for x in range(items.shape[0]):\r\n","        for y in range(data.shape[0]):\r\n","            if data[y, col] == items[x]:\r\n","                count[x] += 1\r\n","    #count has the data of number of times each value is present in\r\n","                \r\n","    for x in range(items.shape[0]):\r\n","        dict[items[x]] = np.empty((int(count[x]), data.shape[1]), dtype=\"|S32\")\r\n","         \r\n","        pos = 0\r\n","        for y in range(data.shape[0]):\r\n","            if data[y, col] == items[x]:\r\n","                dict[items[x]][pos] = data[y]\r\n","                pos += 1     \r\n","        \r\n","        if delete:\r\n","           dict[items[x]] = np.delete(dict[items[x]], col, 1)\r\n","    return items, dict    \r\n","        \r\n","        \r\n","        \r\n","def entropy(S):\r\n","    \"\"\" calculate the entropy \"\"\"\r\n","    items = np.unique(S)\r\n","    if items.size == 1:\r\n","        return 0\r\n","    \r\n","    counts = np.zeros((items.shape[0], 1))\r\n","    sums = 0\r\n","    \r\n","    for x in range(items.shape[0]):\r\n","        counts[x] = sum(S == items[x]) / (S.size)\r\n","        \r\n","    for count in counts:\r\n","        sums += -1 * count * math.log(count, 2)\r\n","    return sums\r\n","    \r\n","def gain_ratio(data, col):\r\n","    items, dict = subtables(data, col, delete=False) \r\n","    #item is the unique value and dict is the data corresponding to it\r\n","    total_size = data.shape[0]\r\n","    entropies = np.zeros((items.shape[0], 1))\r\n","      \r\n","    for x in range(items.shape[0]):\r\n","        ratio = dict[items[x]].shape[0]/(total_size)\r\n","        entropies[x] = ratio * entropy(dict[items[x]][:, -1])\r\n","        \r\n","        \r\n","    total_entropy = entropy(data[:, -1])\r\n","   \r\n","    \r\n","    for x in range(entropies.shape[0]):\r\n","        total_entropy -= entropies[x]\r\n","        \r\n","    return total_entropy\r\n","\r\n","\r\n","def create_node(data, metadata):\r\n","\r\n","    if (np.unique(data[:, -1])).shape[0] == 1: #to check how many rows in last col(yes,no column). shape[0] gives no. of rows \r\n","        ''' if there is only yes or only no then reutrn a node containing the value '''\r\n","        node = Node(\"\")\r\n","        node.answer = np.unique(data[:, -1])\r\n","        return node\r\n","     \r\n","    gains = np.zeros((data.shape[1] - 1, 1))  # data.shape[1] - 1 returns the no of columns in the dataset, minus one to remove last column\r\n","    #size of gains= number of attribute to calculate gain\r\n","    #gains is one dim array (size=4) to store the gain of each attribute \r\n","    \r\n","    for col in range(data.shape[1] - 1):\r\n","        gains[col] = gain_ratio(data, col)\r\n","        \r\n","    split = np.argmax(gains) # argmax returns the index of the max value\r\n","  \r\n","    \r\n","    node = Node(metadata[split])    \r\n","    metadata = np.delete(metadata, split, 0)\r\n","                          \r\n","    \r\n","    items, dict = subtables(data, split, delete=True)\r\n","    \r\n","    for x in range(items.shape[0]):\r\n","        child = create_node(dict[items[x]], metadata)\r\n","        node.children.append((items[x], child))\r\n","    \r\n","    return node        \r\n","    \r\n","def empty(size):\r\n","    \"\"\" To generate empty space needed for shaping the tree\"\"\"\r\n","    s = \"\"\r\n","    for x in range(size):\r\n","        s += \"   \"\r\n","    return s\r\n","\r\n","def print_tree(node, level):\r\n","    if node.answer != \"\":\r\n","\r\n","        print(empty(level), node.answer.item(0).decode(\"utf-8\"))\r\n","        return\r\n","        \r\n","    print(empty(level), node.attribute)\r\n","    \r\n","    for value, n in node.children:\r\n","        print(empty(level + 1), value.tobytes().decode(\"utf-8\"))\r\n","        print_tree(n, level + 2)\r\n","        \r\n","\r\n","metadata, traindata = read_data(\"/content/tennis2.csv\")\r\n","data = np.array(traindata) # to convert the traindata to numpy array \r\n","node = create_node(data, metadata)\r\n","print_tree(node, 0)\r\n","\r\n","\r\n"],"execution_count":6,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:139: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"],"name":"stderr"},{"output_type":"error","ename":"IndexError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-6-f75b2bedacd9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraindata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/tennis2.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraindata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# to convert the traindata to numpy array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m \u001b[0mnode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_node\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m \u001b[0mprint_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-6-f75b2bedacd9>\u001b[0m in \u001b[0;36mcreate_node\u001b[0;34m(data, metadata)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcreate_node\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m#to check how many rows in last col(yes,no column). shape[0] gives no. of rows\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m         \u001b[0;34m''' if there is only yes or only no then reutrn a node containing the value '''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0mnode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mIndexError\u001b[0m: too many indices for array: array is 1-dimensional, but 2 were indexed"]}]}]}